{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/kmk4444/Miuul_deep_learning/blob/main/3_face_recognition_assigment.ipynb",
      "authorship_tag": "ABX9TyP56IvUOlKi8OJ2cavMUBIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Miuul_deep_learning/blob/main/3_face_recognition_assigment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Recognition Assignment"
      ],
      "metadata": {
        "id": "xF8ue6l4nvZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Task 1\n",
        "\n",
        "faces_assignment klasöründe yer alan resimlerin hepsi için age, gender, race ve emotion tespiti yapınız.\n",
        "\n",
        "- age'i olduğu gibi kullanınız\n",
        "- gender için dominat_gender'ı kullanınız\n",
        "- race için dominant race'ı kullanınız\n",
        "- emotion için dominant_emotion'ı kullanınız\n",
        "\n",
        "\n",
        "Çıktıda file_name (yani geziyor olduğunuz dizin bilgisi), age, gender, race ve emotion olmalı.\n",
        "\n",
        "örnek çıktı şu şekilde olmalı:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        " [{'file_name': '/content/faces_lectures/face18.png',\n",
        "  'age': 28,\n",
        "  'gender': 'Man',\n",
        "  'race': 'white',\n",
        "  'emotion': 'sad'},\n",
        " {'file_name': '/content/faces_lectures/face16.png',\n",
        "  'age': 45,\n",
        "  'gender': 'Man',\n",
        "  'race': 'white',\n",
        "  'emotion': 'happy'},\n",
        " {'file_name': '/content/faces_lectures/face17.png',\n",
        "  'age': 31,\n",
        "  'gender': 'Woman',\n",
        "  'race': 'asian',\n",
        "  'emotion': 'happy'},\n",
        " {'file_name': '/content/faces_lectures/face19.png',\n",
        "  'age': 22,\n",
        "  'gender': 'Man',\n",
        "  'race': 'asian',\n",
        "  'emotion': 'happy'},\n",
        " {'file_name': '/content/faces_lectures/face20.png',\n",
        "  'age': 26,\n",
        "  'gender': 'Woman',\n",
        "  'race': 'asian',\n",
        "  'emotion': 'neutral'}]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Dikkat edilmesi gerekenler:\n",
        "\n",
        "  - Tüm işlemleri tek bir fonksiyon yapmalı. fonksiyona sadece root_path yani resimlerin olduğu dizin girilmeli.\n",
        "\n",
        "  - Amelasyon olmamalı, bunun için path'leri gezecek bir döngü ve oluşturulması gerek ve tüm result'ları tutacak olan results'u gezecek olan bir döngü olmalı.\n",
        "\n",
        "  - Sonuçlar return edilmeli."
      ],
      "metadata": {
        "id": "KmIAAdWHnxxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 Solution"
      ],
      "metadata": {
        "id": "BIyRNuBrn0e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "id": "pwyusxAPn_0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "S4CqjBodoCYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def  analyze_images_in_directory(root_path):\n",
        "  image_paths = [os.path.join(root_path, f) for f in os.listdir(root_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "  results = []\n",
        "\n",
        "  for path in image_paths:\n",
        "\n",
        "    result = DeepFace.analyze(path, actions=[\"age\",\"gender\",\"race\",\"emotion\"])\n",
        "\n",
        "    for idx, face in enumerate(result):\n",
        "      results.append({\n",
        "          \"file_name\" : path,\n",
        "          \"age\" : result[0][\"age\"],\n",
        "          \"gender\" : result[0][\"dominant_gender\"],\n",
        "          \"race\" : result[0][\"dominant_race\"],\n",
        "          \"emotion\" : result[0][\"dominant_emotion\"]\n",
        "      })\n",
        "\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "jD9g4zhuorfx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face1.png\"\n",
        "images_path = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment\""
      ],
      "metadata": {
        "id": "4jDVZjOav1cH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = analyze_images_in_directory(images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifake_rNv0A7",
        "outputId": "92660e32-d656-4f7f-bfc5-5e2e21891642"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  2.18it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:01<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face4.png', 'age': 27, 'gender': 'Man', 'race': 'white', 'emotion': 'happy'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face1.png', 'age': 35, 'gender': 'Woman', 'race': 'white', 'emotion': 'fear'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face3.png', 'age': 30, 'gender': 'Woman', 'race': 'white', 'emotion': 'happy'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face5.png', 'age': 25, 'gender': 'Man', 'race': 'middle eastern', 'emotion': 'happy'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face2.png', 'age': 23, 'gender': 'Woman', 'race': 'white', 'emotion': 'happy'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-C-pwVpyfim",
        "outputId": "69559641-85ad-4570-f413-bfcabe776160"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face4.png', 'age': 27, 'gender': 'Man', 'race': 'white', 'emotion': 'happy'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face1.png', 'age': 35, 'gender': 'Woman', 'race': 'white', 'emotion': 'fear'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face3.png', 'age': 30, 'gender': 'Woman', 'race': 'white', 'emotion': 'happy'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face5.png', 'age': 25, 'gender': 'Man', 'race': 'middle eastern', 'emotion': 'happy'}, {'file_name': '/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_assignment/face2.png', 'age': 23, 'gender': 'Woman', 'race': 'white', 'emotion': 'happy'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2\n",
        "\n",
        "Önceki bölümdeki fonksiyonun çıktısını tutarak bu çıktıdaki bilgileri resimlerin üzerine yazdırınız.\n",
        "\n",
        "Önce tek bir görsel için yapınız daha sonra bir dizindeki tüm görseller için yapınız.\n",
        "\n",
        "Fonksiyonun adı visualize_all_attribute olmalı.\n",
        "\n",
        "İpucları:\n",
        "\n",
        "- Fonksiyon iki argumana sahip olmalı: img_path, result\n",
        "\n",
        "- Adı visualize_all_attribute olmalı.\n",
        "\n",
        "- Dersteki if else bloğuna gerek yok.\n",
        "\n",
        "- Sadece title bölümüne odaklanıp bilgiler title'a yansıtmalı. Yani age, gender, race, emotion bilgileri resmin kendisinin üzerine değil uygulamamızdaki gibi olmalı.\n"
      ],
      "metadata": {
        "id": "8Hm7sjJrn14G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2 Solution"
      ],
      "metadata": {
        "id": "iAHS01Srn31o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HQrWAGGolbJg"
      },
      "outputs": [],
      "source": [
        "def visualize_attribute(img_path, result):\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 1.5\n",
        "    thickness = 2\n",
        "    color = (255, 255, 255)\n",
        "    shadow_color = (0, 0, 0)\n",
        "\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Age:{result[0]['age']}, Gender:{result[0]['dominant_gender']}, Race: {result[0]['dominant_race']}, Emotion: {result[0]['dominant_emotion']}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = [os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]"
      ],
      "metadata": {
        "id": "hkf8EAdv36Ip"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_one_picture = DeepFace.analyze(img_path, [\"age\", \"gender\", \"race\", \"emotion\"])\n",
        "visualize_attribute(img_path,result)"
      ],
      "metadata": {
        "id": "QySzL3cJ4-IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in image_paths:\n",
        "\n",
        "  result = DeepFace.analyze(path, [\"age\", \"gender\", \"race\", \"emotion\"])\n",
        "\n",
        "  visualize_attribute(path,result)"
      ],
      "metadata": {
        "id": "x1N2-aeE0hQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
