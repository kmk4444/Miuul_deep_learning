{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/kmk4444/Miuul_deep_learning/blob/main/2_face_recognition.ipynb",
      "authorship_tag": "ABX9TyPipQ6h6WyE57ZfWjD4Wm3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Miuul_deep_learning/blob/main/2_face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Recognition\n",
        "\n",
        "Deepface is a lightweight face recognition and facial attribute analysis (age, gender, emotion and race) framework for python. It is a hybrid face recognition framework wrapping state-of-the-art models: VGG-Face, FaceNet, OpenFace, DeepFace, DeepID, ArcFace, Dlib, SFace and GhostFaceNet.\n",
        "\n",
        "https://github.com/serengil/deepface\n",
        "\n"
      ],
      "metadata": {
        "id": "Kt9XsHCpm0dD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsIiHmDAmZ_r"
      },
      "outputs": [],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzWZrRwynOsJ",
        "outputId": "de1d43cf-1dc8-471f-9d2d-b76be5859a7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-08-27 11:34:48 - Directory /root/.deepface has been created\n",
            "24-08-27 11:34:48 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_lecture/face16.png\"\n",
        "images_path = \"/content/drive/MyDrive/Colab Notebooks/deep_learning_course_materials/01_introduction/face_recognition_files/faces_lecture\""
      ],
      "metadata": {
        "id": "NEfk59RGnjed"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Age Detection"
      ],
      "metadata": {
        "id": "cCoyiwYAn9UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DeepFace.analyze(img_path=img_path, actions=['age'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyewWRb-oCiK",
        "outputId": "2fd873f5-c026-4fc1-f79e-6f786bf328bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'age': 46,\n",
              "  'region': {'x': 229,\n",
              "   'y': 447,\n",
              "   'w': 1442,\n",
              "   'h': 1442,\n",
              "   'left_eye': None,\n",
              "   'right_eye': None},\n",
              "  'face_confidence': 0.93}]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = DeepFace.analyze(img_path=img_path, actions=['age'])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d3kIkvvoT12",
        "outputId": "66c5e692-126f-41dd-cc3e-a80056a92185"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 46, 'region': {'x': 229, 'y': 447, 'w': 1442, 'h': 1442, 'left_eye': None, 'right_eye': None}, 'face_confidence': 0.93}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[0][\"age\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAiTc9dDpFQ_",
        "outputId": "568b9b2d-6ffd-475a-85ae-d1681d9ad9fe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_attribute(img_path, result, attribute=\"age\"):\n",
        "    # Load the image in color mode\n",
        "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Image not found or unable to load at path: {img_path}\")\n",
        "\n",
        "    # Convert the image from BGR to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Retrieve the attribute from the result\n",
        "    if attribute in result[0]:\n",
        "        prediction = result[0][attribute]\n",
        "        text = f\"{attribute}: {prediction}\"\n",
        "    else:\n",
        "        text = f\"{attribute} not found in result\"\n",
        "\n",
        "    # Display the image with the attribute text\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(text)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "O2oGEzQLow7w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_attribute(img_path, result, \"age\")"
      ],
      "metadata": {
        "id": "-rAmCKUpp9L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = [os.path.join(images_path,f)for f in os.listdir(images_path) if f.endswith(('.jpg','.jpeg','.png'))]"
      ],
      "metadata": {
        "id": "dj5fQR-vv3zI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths"
      ],
      "metadata": {
        "id": "h8d59aoXx7H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in image_paths:\n",
        "  result = DeepFace.analyze(path, actions=['age'])\n",
        "  visualize_attribute(path, result)\n"
      ],
      "metadata": {
        "id": "n9wqmdhlyJtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gender Detection"
      ],
      "metadata": {
        "id": "yJryaRq4zRMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DeepFace.analyze(img_path=img_path, actions=['gender'])"
      ],
      "metadata": {
        "id": "7Mg7AO59zsfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_attribute(img_path,result, \"gender\")"
      ],
      "metadata": {
        "id": "yVVcxghhzupf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in image_paths:\n",
        "  result= DeepFace.analyze(path,actions=['gender'])\n",
        "  visualize_attribute(path, result, \"gender\")"
      ],
      "metadata": {
        "id": "OgiNW3l0z0La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Race Detection"
      ],
      "metadata": {
        "id": "A2l9k-He0F7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DeepFace.analyze(img_path=img_path, actions=[\"race\"])"
      ],
      "metadata": {
        "id": "F2PArqxe0HmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in image_paths:\n",
        "  result = DeepFace.analyze(path, actions=['race'])\n",
        "  visualize_attribute(path, result, \"race\")"
      ],
      "metadata": {
        "id": "qh1WQ_xs0PlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emotion Detection"
      ],
      "metadata": {
        "id": "PZlv-5o00VId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DeepFace.analyze(img_path=img_path, actions=['emotion'])"
      ],
      "metadata": {
        "id": "Fjs-_gUh0XKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in image_paths:\n",
        "  result = DeepFace.analyze(path, actions=[\"emotion\"])\n",
        "  visualize_attribute(path, result, \"emotion\")"
      ],
      "metadata": {
        "id": "4jroBs8J0eB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}